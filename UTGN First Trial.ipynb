{"cells":[{"cell_type":"markdown","metadata":{"id":"erRFpC-Fp9LB"},"source":["Dataset: https://www.tensorflow.org/datasets/catalog/protein_net#protein_netcasp12\n","\n","to use it: https://tf.wiki/en/appendix/tfds.html\n","\n","Paper: https://arxiv.org/pdf/1908.00723v1.pdf\n","\n","file:///D:/Study/Bioinformatics/project/1908.00723v1.pdf\n","\n","https://paperswithcode.com/paper/universal-transforming-geometric-network\n","\n","Official code: https://github.com/JinLi711/UTGN/tree/master/UTGN/model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Az0q8LUjxQPF"},"source":["# New section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOI7yZOnwuoR"},"outputs":[],"source":["pip install -q tfds-nightly tensorflow matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBFJctJmpqfh"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KsNps4HPyhOx"},"outputs":[],"source":["# import tensorflow_datasets\n","from tensorflow_datasets.structured.proteinnet import ProteinNet\n","from tensorflow_datasets.core.dataset_builder import BuilderConfig\n","from tensorflow_datasets.core.utils.version import Version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1640993325068,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"mjQUGxxj0tpG","outputId":"bbb27b81-a5af-4e7d-a0c2-d7b4891d8af4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Help on class ProteinNet in module tensorflow_datasets.structured.proteinnet.proteinnet:\n","\n","class ProteinNet(tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder)\n"," |  ProteinNet(*, data_dir: Union[str, os.PathLike, NoneType] = None, config: Union[NoneType, str, tensorflow_datasets.core.dataset_builder.BuilderConfig] = None, version: Union[NoneType, str, tensorflow_datasets.core.utils.version.Version] = None)\n"," |  \n"," |  DatasetBuilder for the ProteinNet dataset.\n"," |  \n"," |  Method resolution order:\n"," |      ProteinNet\n"," |      tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder\n"," |      tensorflow_datasets.core.dataset_builder.FileAdapterBuilder\n"," |      tensorflow_datasets.core.dataset_builder.FileReaderBuilder\n"," |      tensorflow_datasets.core.dataset_builder.DatasetBuilder\n"," |      tensorflow_datasets.core.registered.RegisteredDataset\n"," |      abc.ABC\n"," |      builtins.object\n"," |  \n"," |  Data and other attributes defined here:\n"," |  \n"," |  AMINOACIDS = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', '...\n"," |  \n"," |  BUILDER_CONFIGS = [BuilderConfig(name='casp7', version=None, releas......\n"," |  \n"," |  FILES = {'casp10': 'casp10.tar.gz', 'casp11': 'casp11.tar.gz', 'casp12...\n"," |  \n"," |  RELEASE_NOTES = {'1.0.0': 'Initial release.'}\n"," |  \n"," |  THRESHOLDS = [30, 50, 70, 90, 95, 100]\n"," |  \n"," |  URL = 'https://sharehost.hms.harvard.edu/sysbio/alquraishi/proteinnet/...\n"," |  \n"," |  VERSION = Version('1.0.0')\n"," |  \n"," |  __abstractmethods__ = frozenset()\n"," |  \n"," |  name = 'protein_net'\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __init__(self, *, data_dir: Union[str, os.PathLike, NoneType] = None, config: Union[NoneType, str, tensorflow_datasets.core.dataset_builder.BuilderConfig] = None, version: Union[NoneType, str, tensorflow_datasets.core.utils.version.Version] = None)\n"," |      Constructs a DatasetBuilder.\n"," |      \n"," |      Callers must pass arguments as keyword arguments.\n"," |      \n"," |      Args:\n"," |        data_dir: directory to read/write data. Defaults to the value of\n"," |          the environment variable TFDS_DATA_DIR, if set, otherwise falls back to\n"," |          \"~/tensorflow_datasets\".\n"," |        config: `tfds.core.BuilderConfig` or `str` name, optional configuration\n"," |          for the dataset that affects the data generated on disk. Different\n"," |          `builder_config`s will have their own subdirectories and versions.\n"," |        version: Optional version at which to load the dataset. An error is\n"," |          raised if specified version cannot be satisfied. Eg: '1.2.3', '1.2.*'.\n"," |          The special value \"experimental_latest\" will use the highest version,\n"," |          even if not default. This is not recommended unless you know what you\n"," |          are doing, as the version could be broken.\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  as_dataset(self, split=None, *, batch_size=None, shuffle_files=False, decoders=None, read_config=None, as_supervised=False)\n"," |      Constructs a `tf.data.Dataset`.\n"," |      \n"," |      Callers must pass arguments as keyword arguments.\n"," |      \n"," |      The output types vary depending on the parameters. Examples:\n"," |      \n"," |      ```python\n"," |      builder = tfds.builder('imdb_reviews')\n"," |      builder.download_and_prepare()\n"," |      \n"," |      # Default parameters: Returns the dict of tf.data.Dataset\n"," |      ds_all_dict = builder.as_dataset()\n"," |      assert isinstance(ds_all_dict, dict)\n"," |      print(ds_all_dict.keys())  # ==\u003e ['test', 'train', 'unsupervised']\n"," |      \n"," |      assert isinstance(ds_all_dict['test'], tf.data.Dataset)\n"," |      # Each dataset (test, train, unsup.) consists of dictionaries\n"," |      # {'label': \u003ctf.Tensor: .. dtype=int64, numpy=1\u003e,\n"," |      #  'text': \u003ctf.Tensor: .. dtype=string, numpy=b\"I've watched the movie ..\"\u003e}\n"," |      # {'label': \u003ctf.Tensor: .. dtype=int64, numpy=1\u003e,\n"," |      #  'text': \u003ctf.Tensor: .. dtype=string, numpy=b'If you love Japanese ..'\u003e}\n"," |      \n"," |      # With as_supervised: tf.data.Dataset only contains (feature, label) tuples\n"," |      ds_all_supervised = builder.as_dataset(as_supervised=True)\n"," |      assert isinstance(ds_all_supervised, dict)\n"," |      print(ds_all_supervised.keys())  # ==\u003e ['test', 'train', 'unsupervised']\n"," |      \n"," |      assert isinstance(ds_all_supervised['test'], tf.data.Dataset)\n"," |      # Each dataset (test, train, unsup.) consists of tuples (text, label)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      \n"," |      # Same as above plus requesting a particular split\n"," |      ds_test_supervised = builder.as_dataset(as_supervised=True, split='test')\n"," |      assert isinstance(ds_test_supervised, tf.data.Dataset)\n"," |      # The dataset consists of tuples (text, label)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      ```\n"," |      \n"," |      Args:\n"," |        split: Which split of the data to load (e.g. `'train'`, `'test'`\n"," |          `['train', 'test']`, `'train[80%:]'`,...). See our\n"," |          [split API guide](https://www.tensorflow.org/datasets/splits).\n"," |          If `None`, will return all splits in a `Dict[Split, tf.data.Dataset]`.\n"," |        batch_size: `int`, batch size. Note that variable-length features will\n"," |          be 0-padded if `batch_size` is set. Users that want more custom behavior\n"," |          should use `batch_size=None` and use the `tf.data` API to construct a\n"," |          custom pipeline. If `batch_size == -1`, will return feature\n"," |          dictionaries of the whole dataset with `tf.Tensor`s instead of a\n"," |          `tf.data.Dataset`.\n"," |        shuffle_files: `bool`, whether to shuffle the input files. Defaults to\n"," |          `False`.\n"," |        decoders: Nested dict of `Decoder` objects which allow to customize the\n"," |          decoding. The structure should match the feature structure, but only\n"," |          customized feature keys need to be present. See\n"," |          [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n"," |          for more info.\n"," |        read_config: `tfds.ReadConfig`, Additional options to configure the\n"," |          input pipeline (e.g. seed, num parallel reads,...).\n"," |        as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n"," |          will have a 2-tuple structure `(input, label)` according to\n"," |          `builder.info.supervised_keys`. If `False`, the default,\n"," |          the returned `tf.data.Dataset` will have a dictionary with all the\n"," |          features.\n"," |      \n"," |      Returns:\n"," |        `tf.data.Dataset`, or if `split=None`, `dict\u003ckey: tfds.Split, value:\n"," |        tfds.data.Dataset\u003e`.\n"," |      \n"," |        If `batch_size` is -1, will return feature dictionaries containing\n"," |        the entire dataset in `tf.Tensor`s instead of a `tf.data.Dataset`.\n"," |  \n"," |  download_and_prepare(self, *, download_dir=None, download_config=None)\n"," |      Downloads and prepares dataset for reading.\n"," |      \n"," |      Args:\n"," |        download_dir: `str`, directory where downloaded files are stored.\n"," |          Defaults to \"~/tensorflow-datasets/downloads\".\n"," |        download_config: `tfds.download.DownloadConfig`, further configuration for\n"," |          downloading and preparing dataset.\n"," |      \n"," |      Raises:\n"," |        IOError: if there is not enough disk space available.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n"," |  \n"," |  builder_config\n"," |      `tfds.core.BuilderConfig` for this builder.\n"," |  \n"," |  builder_configs\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  canonical_version\n"," |  \n"," |  code_path\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  data_dir\n"," |  \n"," |  info\n"," |      `tfds.core.DatasetInfo` for this builder.\n"," |  \n"," |  supported_versions\n"," |  \n"," |  url_infos\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  version\n"," |  \n"," |  versions\n"," |      Versions (canonical + availables), in preference order.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from tensorflow_datasets.core.dataset_builder.DatasetBuilder:\n"," |  \n"," |  MANUAL_DOWNLOAD_INSTRUCTIONS = None\n"," |  \n"," |  SUPPORTED_VERSIONS = []\n"," |  \n"," |  __annotations__ = {'RELEASE_NOTES': typing.ClassVar[typing.Dict[str, s...\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n"," |  \n"," |  __init_subclass__(skip_registration=False, **kwargs) from abc.ABCMeta\n"," |      This method is called when a class is subclassed.\n"," |      \n"," |      The default implementation does nothing. It may be\n"," |      overridden to extend subclasses.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"]}],"source":["help(ProteinNet)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1640994845103,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"fPdqWiTd5Yex","outputId":"54203eb0-8f57-4ec3-e333-37db101d5607"},"outputs":[{"name":"stdout","output_type":"stream","text":["Help on class GeneratorBasedBuilder in module tensorflow_datasets.core.dataset_builder:\n","\n","class GeneratorBasedBuilder(FileAdapterBuilder)\n"," |  GeneratorBasedBuilder(*, data_dir: Union[str, os.PathLike, NoneType] = None, config: Union[NoneType, str, tensorflow_datasets.core.dataset_builder.BuilderConfig] = None, version: Union[NoneType, str, tensorflow_datasets.core.utils.version.Version] = None)\n"," |  \n"," |  Base class for datasets with data generation based on dict generators.\n"," |  \n"," |  `GeneratorBasedBuilder` is a convenience class that abstracts away much\n"," |  of the data writing and reading of `DatasetBuilder`. It expects subclasses to\n"," |  implement generators of feature dictionaries across the dataset splits\n"," |  `_split_generators`. See the method docstrings for details.\n"," |  \n"," |  Method resolution order:\n"," |      GeneratorBasedBuilder\n"," |      FileAdapterBuilder\n"," |      FileReaderBuilder\n"," |      DatasetBuilder\n"," |      tensorflow_datasets.core.registered.RegisteredDataset\n"," |      abc.ABC\n"," |      builtins.object\n"," |  \n"," |  Data and other attributes defined here:\n"," |  \n"," |  __abstractmethods__ = frozenset({'_generate_examples', '_info', '_spli...\n"," |  \n"," |  name = 'generator_based_builder'\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from DatasetBuilder:\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __init__(self, *, data_dir: Union[str, os.PathLike, NoneType] = None, config: Union[NoneType, str, tensorflow_datasets.core.dataset_builder.BuilderConfig] = None, version: Union[NoneType, str, tensorflow_datasets.core.utils.version.Version] = None)\n"," |      Constructs a DatasetBuilder.\n"," |      \n"," |      Callers must pass arguments as keyword arguments.\n"," |      \n"," |      Args:\n"," |        data_dir: directory to read/write data. Defaults to the value of\n"," |          the environment variable TFDS_DATA_DIR, if set, otherwise falls back to\n"," |          \"~/tensorflow_datasets\".\n"," |        config: `tfds.core.BuilderConfig` or `str` name, optional configuration\n"," |          for the dataset that affects the data generated on disk. Different\n"," |          `builder_config`s will have their own subdirectories and versions.\n"," |        version: Optional version at which to load the dataset. An error is\n"," |          raised if specified version cannot be satisfied. Eg: '1.2.3', '1.2.*'.\n"," |          The special value \"experimental_latest\" will use the highest version,\n"," |          even if not default. This is not recommended unless you know what you\n"," |          are doing, as the version could be broken.\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  as_dataset(self, split=None, *, batch_size=None, shuffle_files=False, decoders=None, read_config=None, as_supervised=False)\n"," |      Constructs a `tf.data.Dataset`.\n"," |      \n"," |      Callers must pass arguments as keyword arguments.\n"," |      \n"," |      The output types vary depending on the parameters. Examples:\n"," |      \n"," |      ```python\n"," |      builder = tfds.builder('imdb_reviews')\n"," |      builder.download_and_prepare()\n"," |      \n"," |      # Default parameters: Returns the dict of tf.data.Dataset\n"," |      ds_all_dict = builder.as_dataset()\n"," |      assert isinstance(ds_all_dict, dict)\n"," |      print(ds_all_dict.keys())  # ==\u003e ['test', 'train', 'unsupervised']\n"," |      \n"," |      assert isinstance(ds_all_dict['test'], tf.data.Dataset)\n"," |      # Each dataset (test, train, unsup.) consists of dictionaries\n"," |      # {'label': \u003ctf.Tensor: .. dtype=int64, numpy=1\u003e,\n"," |      #  'text': \u003ctf.Tensor: .. dtype=string, numpy=b\"I've watched the movie ..\"\u003e}\n"," |      # {'label': \u003ctf.Tensor: .. dtype=int64, numpy=1\u003e,\n"," |      #  'text': \u003ctf.Tensor: .. dtype=string, numpy=b'If you love Japanese ..'\u003e}\n"," |      \n"," |      # With as_supervised: tf.data.Dataset only contains (feature, label) tuples\n"," |      ds_all_supervised = builder.as_dataset(as_supervised=True)\n"," |      assert isinstance(ds_all_supervised, dict)\n"," |      print(ds_all_supervised.keys())  # ==\u003e ['test', 'train', 'unsupervised']\n"," |      \n"," |      assert isinstance(ds_all_supervised['test'], tf.data.Dataset)\n"," |      # Each dataset (test, train, unsup.) consists of tuples (text, label)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      \n"," |      # Same as above plus requesting a particular split\n"," |      ds_test_supervised = builder.as_dataset(as_supervised=True, split='test')\n"," |      assert isinstance(ds_test_supervised, tf.data.Dataset)\n"," |      # The dataset consists of tuples (text, label)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"I've watched the movie ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      # (\u003ctf.Tensor: ... dtype=string, numpy=b\"If you love Japanese ..\"\u003e,\n"," |      #  \u003ctf.Tensor: ... dtype=int64, numpy=1\u003e)\n"," |      ```\n"," |      \n"," |      Args:\n"," |        split: Which split of the data to load (e.g. `'train'`, `'test'`\n"," |          `['train', 'test']`, `'train[80%:]'`,...). See our\n"," |          [split API guide](https://www.tensorflow.org/datasets/splits).\n"," |          If `None`, will return all splits in a `Dict[Split, tf.data.Dataset]`.\n"," |        batch_size: `int`, batch size. Note that variable-length features will\n"," |          be 0-padded if `batch_size` is set. Users that want more custom behavior\n"," |          should use `batch_size=None` and use the `tf.data` API to construct a\n"," |          custom pipeline. If `batch_size == -1`, will return feature\n"," |          dictionaries of the whole dataset with `tf.Tensor`s instead of a\n"," |          `tf.data.Dataset`.\n"," |        shuffle_files: `bool`, whether to shuffle the input files. Defaults to\n"," |          `False`.\n"," |        decoders: Nested dict of `Decoder` objects which allow to customize the\n"," |          decoding. The structure should match the feature structure, but only\n"," |          customized feature keys need to be present. See\n"," |          [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\n"," |          for more info.\n"," |        read_config: `tfds.ReadConfig`, Additional options to configure the\n"," |          input pipeline (e.g. seed, num parallel reads,...).\n"," |        as_supervised: `bool`, if `True`, the returned `tf.data.Dataset`\n"," |          will have a 2-tuple structure `(input, label)` according to\n"," |          `builder.info.supervised_keys`. If `False`, the default,\n"," |          the returned `tf.data.Dataset` will have a dictionary with all the\n"," |          features.\n"," |      \n"," |      Returns:\n"," |        `tf.data.Dataset`, or if `split=None`, `dict\u003ckey: tfds.Split, value:\n"," |        tfds.data.Dataset\u003e`.\n"," |      \n"," |        If `batch_size` is -1, will return feature dictionaries containing\n"," |        the entire dataset in `tf.Tensor`s instead of a `tf.data.Dataset`.\n"," |  \n"," |  download_and_prepare(self, *, download_dir=None, download_config=None)\n"," |      Downloads and prepares dataset for reading.\n"," |      \n"," |      Args:\n"," |        download_dir: `str`, directory where downloaded files are stored.\n"," |          Defaults to \"~/tensorflow-datasets/downloads\".\n"," |        download_config: `tfds.download.DownloadConfig`, further configuration for\n"," |          downloading and preparing dataset.\n"," |      \n"," |      Raises:\n"," |        IOError: if there is not enough disk space available.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from DatasetBuilder:\n"," |  \n"," |  builder_config\n"," |      `tfds.core.BuilderConfig` for this builder.\n"," |  \n"," |  builder_configs\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  canonical_version\n"," |  \n"," |  code_path\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  data_dir\n"," |  \n"," |  info\n"," |      `tfds.core.DatasetInfo` for this builder.\n"," |  \n"," |  supported_versions\n"," |  \n"," |  url_infos\n"," |      classmethod(function) -\u003e method\n"," |      \n"," |      Convert a function to be a class method.\n"," |      \n"," |      A class method receives the class as implicit first argument,\n"," |      just like an instance method receives the instance.\n"," |      To declare a class method, use this idiom:\n"," |      \n"," |        class C:\n"," |            @classmethod\n"," |            def f(cls, arg1, arg2, ...):\n"," |                ...\n"," |      \n"," |      It can be called either on the class (e.g. C.f()) or on an instance\n"," |      (e.g. C().f()).  The instance is ignored except for its class.\n"," |      If a class method is called for a derived class, the derived class\n"," |      object is passed as the implied first argument.\n"," |      \n"," |      Class methods are different than C++ or Java static methods.\n"," |      If you want those, see the staticmethod builtin.\n"," |  \n"," |  version\n"," |  \n"," |  versions\n"," |      Versions (canonical + availables), in preference order.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from DatasetBuilder:\n"," |  \n"," |  BUILDER_CONFIGS = []\n"," |  \n"," |  MANUAL_DOWNLOAD_INSTRUCTIONS = None\n"," |  \n"," |  RELEASE_NOTES = {}\n"," |  \n"," |  SUPPORTED_VERSIONS = []\n"," |  \n"," |  VERSION = None\n"," |  \n"," |  __annotations__ = {'RELEASE_NOTES': typing.ClassVar[typing.Dict[str, s...\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n"," |  \n"," |  __init_subclass__(skip_registration=False, **kwargs) from abc.ABCMeta\n"," |      This method is called when a class is subclassed.\n"," |      \n"," |      The default implementation does nothing. It may be\n"," |      overridden to extend subclasses.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from tensorflow_datasets.core.registered.RegisteredDataset:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"]}],"source":["from tensorflow_datasets.core.dataset_builder import DatasetBuilder\n","help(tensorflow_datasets.core.dataset_builder.GeneratorBasedBuilder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-o0z_kj5SLK"},"outputs":[],"source":["ProteinNet()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"elapsed":314,"status":"error","timestamp":1640993992721,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"QaKiVd2C2xF2","outputId":"544bba72-4226-4845-bb71-1fa01c0b6e51"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-41-dc12358e1a5f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProteinNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.0.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, config, version)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mbuilder_config\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mown\u001b[0m \u001b[0msubdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mat\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAn\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 181\u001b[0;31m         \u001b[0mraised\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msatisfied\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mEg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.2.*'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m           \u001b[0mThe\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m\"experimental_latest\"\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m           \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0munless\u001b[0m \u001b[0myou\u001b[0m \u001b[0mknow\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_create_builder_config\u001b[0;34m(self, builder_config)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 833\u001b[0;31m       \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m     \"\"\"\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: BuilderConfig casp7 must have a version"]}],"source":["help(ProteinNet(version = Version('1.0.0')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"elapsed":316,"status":"error","timestamp":1640994039455,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"w6vL16E6110b","outputId":"768d8c64-cfc9-47e5-a173-fb6b2d8e15ae"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-42-1e1b8f879b55\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mPn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProteinNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'casp12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.0.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, config, version)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mbuilder_config\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mown\u001b[0m \u001b[0msubdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mat\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAn\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 181\u001b[0;31m         \u001b[0mraised\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msatisfied\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mEg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.2.*'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m           \u001b[0mThe\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m\"experimental_latest\"\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m           \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0munless\u001b[0m \u001b[0myou\u001b[0m \u001b[0mknow\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_create_builder_config\u001b[0;34m(self, builder_config)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 833\u001b[0;31m       \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m     \"\"\"\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: BuilderConfig casp12 must have a version"]}],"source":["Pn = ProteinNet(config = 'casp12', version = Version('1.0.0'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"elapsed":317,"status":"error","timestamp":1640993506861,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"4Byv2GLZwks8","outputId":"db8c0d08-321f-4dcd-bb97-8315a0d624e7"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-32-443734777fa4\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProteinNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"protein_net/casp12\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# With as_supervised: tf.data.Dataset only contains (feature, label) tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0mds_all_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 511\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_all_supervised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_all_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ==\u003e ['test', 'train', 'unsupervised']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_data_dir'"]}],"source":["dataset = ProteinNet.as_dataset(\"protein_net/casp12\", split=['train', 'test'], as_supervised=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":344,"status":"error","timestamp":1640993140392,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"XKln-_H2z970","outputId":"ae67eb44-5a38-4b9f-e784-7ad1147d12bf"},"outputs":[{"ename":"DatasetNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-19-587b4240cb2f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"protein_net/casp12\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mcurrent_version\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVersion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mextra_versions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVersion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 341\u001b[0;31m     \u001b[0mcurrent_version_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m ) -\u003e Iterable[str]:\n\u001b[1;32m    343\u001b[0m   \u001b[0;34m\"\"\"Returns the list of all current versions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 210\u001b[0;31m     \u001b[0mtry_gcs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m ):\n\u001b[1;32m    212\u001b[0m   \u001b[0;31m# pylint: disable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, data_dir, **builder_init_kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# Requested version require original code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Code does not exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;34m'version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Version explicitly given (unlock backward compatibility)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       raise ValueError(\n\u001b[0;32m--\u003e 145\u001b[0;31m           \u001b[0;34mf'Cannot have both `try_gcs=True` and `data_dir={data_dir}` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m           'explicitly set')\n\u001b[1;32m    147\u001b[0m     \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcs_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcs_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset protein_net not found. Available datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- downsampled_imagenet\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kitti\n\t- kmnist\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- qa4mre\n\t- qasc\n\t- quickdraw_bitmap\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- resisc45\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- starcraft_video\n\t- stl10\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- vgg_face2\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- xnli\n\t- xquad\n\t- xsum\n\t- yelp_polarity_reviews\n\t- yes_no\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n"]}],"source":["dataset = tfds.load(\"protein_net/casp12\", split=tfds.Split.TRAIN, as_supervised=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nR12LAat0Cp9"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ps4QjLN1xSxx"},"source":["# UTGN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2075,"status":"ok","timestamp":1642376732768,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"AtPB9-aXxY_T","outputId":"3464e964-b338-45ed-f639-ef636c26a693"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'UTGN'...\n","remote: Enumerating objects: 490, done.\u001b[K\n","remote: Total 490 (delta 0), reused 0 (delta 0), pack-reused 490\u001b[K\n","Receiving objects: 100% (490/490), 57.67 MiB | 44.60 MiB/s, done.\n","Resolving deltas: 100% (335/335), done.\n"]}],"source":["!git clone https://github.com/JinLi711/UTGN.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1642376732771,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"jMYefGBQK658","outputId":"aaa5ca5b-e571-4838-fe4a-9ef40abb5e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Jan 16 23:47:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzVdCp3lJsYU"},"outputs":[],"source":["!mkdir -p /content/UTGN/UTGN/runs/CASP12/casp12/\n","!mkdir -p /content/UTGN/UTGN/checkpoints/\n","!mkdir -p /content/UTGN/UTGN/logs/"]},{"cell_type":"markdown","metadata":{"id":"8xNaPGoL4K_5"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"Mh4OSzFv73M3"},"source":["https://github.com/aqlaboratory/proteinnet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388549,"status":"ok","timestamp":1642377121898,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"MlX0vvzm4Kjg","outputId":"e74055df-e26d-43f5-ef94-ec9ca4fd1f1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/UTGN/UTGN/data\n","--2022-01-16 23:47:56--  https://sharehost.hms.harvard.edu/sysbio/alquraishi/proteinnet/tfrecords/casp12.tar.gz\n","Resolving sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)... 134.174.159.103\n","Connecting to sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)|134.174.159.103|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7318605789 (6.8G) [application/x-gzip]\n","Saving to: casp12.tar.gz\n","\n","casp12.tar.gz       100%[===================\u003e]   6.82G  55.2MB/s    in 2m 16s  \n","\n","2022-01-16 23:50:12 (51.5 MB/s) - casp12.tar.gz saved [7318605789/7318605789]\n","\n"]}],"source":["%mkdir /content/UTGN/UTGN/data\n","%cd /content/UTGN/UTGN/data\n","!wget https://sharehost.hms.harvard.edu/sysbio/alquraishi/proteinnet/tfrecords/casp12.tar.gz\n","!tar -xf casp12.tar.gz\n","%rm /content/UTGN/UTGN/data/casp12.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1rs5eljWkSawobhYY08gJlPH5KSNR741z"},"executionInfo":{"elapsed":46285,"status":"ok","timestamp":1642378113415,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"VaKghxj3W60w","outputId":"93251a7a-d8cb-4c4e-d689-324b3f19d1ee"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["!cat /content/UTGN/UTGN/data/casp12/training/1"]},{"cell_type":"markdown","metadata":{"id":"Q-vMPbBQAEwB"},"source":["## Config."]},{"cell_type":"markdown","metadata":{"id":"tD6YPuAARd-I"},"source":["Upload config\n","\n","utils.py     change line 29 to return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zF9KT3G5BfZ2"},"outputs":[],"source":["!mv /content/casp12.config \"/content/UTGN/UTGN/runs/CASP12/casp12/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3909,"status":"ok","timestamp":1642377126921,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"JLdYcGY8I1iY","outputId":"40539aa6-8cf6-4162-b094-94f9fe505e3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51216,"status":"ok","timestamp":1642377178133,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"dk3WpqMrg_FT","outputId":"e5adad4f-0887-4d0f-a622-8f4323be80a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-gpu==1.15\n","  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n","\u001b[K     || 411.5 MB 7.9 kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing\u003e=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n","Requirement already satisfied: tensorboard\u003c1.16.0,\u003e=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: grpcio\u003e=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.43.0)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n","Requirement already satisfied: protobuf\u003e=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: keras-applications\u003e=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.0.8)\n","Requirement already satisfied: numpy\u003c2.0,\u003e=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.19.5)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: wrapt\u003e=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.13.3)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15) (1.15.1)\n","Requirement already satisfied: absl-py\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.12.0)\n","Requirement already satisfied: astor\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Requirement already satisfied: google-pasta\u003e=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications\u003e=1.0.8-\u003etensorflow-gpu==1.15) (3.1.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (57.4.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.3.6)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (4.10.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.10.0.2)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.7.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py-\u003ekeras-applications\u003e=1.0.8-\u003etensorflow-gpu==1.15) (1.5.2)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=6fb2c944f148f7a485345307f1f9bb96db07910b61c064b2a396c2a05c10990e\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: gast, tensorflow-gpu\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.6 requires tensorflow\u003e=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 tensorflow-gpu-1.15.0\n"]}],"source":["pip install tensorflow-gpu==1.15"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2767,"status":"ok","timestamp":1642377180883,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"tn8pP5ilI9T1","outputId":"a1ded903-358a-4706-9d75-5dffdaf02756"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.15.2\n"]}],"source":["import tensorflow\n","print(tensorflow.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1331,"status":"ok","timestamp":1641568986334,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"7NJu335KULqU","outputId":"f1ddb589-912b-4d77-9e50-f185e55785e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.12.0 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.6.0, 2.6.1, 2.6.2, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.8.0rc0)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow-gpu==1.12.0\u001b[0m\n"]}],"source":["# pip install tensorflow==1.13.2\n","# !pip install tensorflow-gpu==1.12.0"]},{"cell_type":"markdown","metadata":{"id":"o2II-7BoILjv"},"source":["Downgrade cuda version"]},{"cell_type":"markdown","metadata":{"id":"WSfRvecsIKOp"},"source":["https://stackoverflow.com/questions/51888118/how-to-downgrade-tensorflow-version-in-colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqGIkDTKH-6I"},"outputs":[],"source":["# !wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","# !dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","# !apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n","# !apt-get update\n","# !apt-get install cuda=9.0.176-1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476,"status":"ok","timestamp":1641643182361,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"YHxzkoTvIT3S","outputId":"c5e73a68-a981-4ff4-8a15-7f3f0a09a975"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2017 NVIDIA Corporation\n","Built on Fri_Sep__1_21:08:03_CDT_2017\n","Cuda compilation tools, release 9.0, V9.0.176\n"]}],"source":["!nvcc --version\n"]},{"cell_type":"markdown","metadata":{"id":"IfmaYjWqymB0"},"source":["## Train a new model or continue training an existing model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXLINKelyls1"},"outputs":[],"source":["# \u003cbaseDirectory\u003e/runs/\u003crunName\u003e/\u003cdatasetName\u003e/\u003cconfigurationFile\u003e\n","# datasetName ProteinNet12Thinning90\n","# \u003cbaseDirectory\u003e/data/\u003cdatasetName\u003e/[training,validation,testing]\n","baseDirectory = \"/content/UTGN/UTGN/\"\n","configurationFilePath = \"/content/UTGN/UTGN/runs/CASP12/casp12/casp12.config\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17517,"status":"ok","timestamp":1642377861402,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"jeVyAF25x0Mx","outputId":"467c50cc-18d9-4124-fc99-a12d605a36de"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/UTGN/UTGN/model\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"]}],"source":["%cd /content/UTGN/UTGN/model\n","!python main.py \"/content/UTGN/UTGN/runs/CASP12/casp12/casp12.config\" -d \"/content/UTGN/UTGN/\" -c"]},{"cell_type":"markdown","metadata":{"id":"DDJMokFCYnVZ"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":426,"status":"ok","timestamp":1642378505915,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"jQ7XVmkRYyNT","outputId":"ba6abad3-8ac4-4abd-b112-b68d35d0b37a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/UTGN/UTGN/model'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189669,"status":"ok","timestamp":1642378699440,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"IurbWgMXYnwx","outputId":"2be2b125-901e-4f69-d03f-8765f8a1048d"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-01-17 00:17:33--  https://sharehost.hms.harvard.edu/sysbio/alquraishi/rgn_models/RGN12.tar.gz\n","Resolving sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)... 134.174.159.103\n","Connecting to sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)|134.174.159.103|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3095423957 (2.9G) [application/x-gzip]\n","Saving to: RGN12.tar.gz\n","\n","RGN12.tar.gz        100%[===================\u003e]   2.88G  30.3MB/s    in 42s     \n","\n","2022-01-17 00:18:15 (70.0 MB/s) - RGN12.tar.gz saved [3095423957/3095423957]\n","\n"]}],"source":["!wget https://sharehost.hms.harvard.edu/sysbio/alquraishi/rgn_models/RGN12.tar.gz\n","!tar -xf RGN12.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhBwC4OUZdqZ"},"outputs":[],"source":["!mv /content/UTGN/UTGN/model/RGN12/data/ProteinNet12Thinning90 /content/UTGN/UTGN/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDMtCpiXZ6vN"},"outputs":[],"source":["!mkdir -p /content/UTGN/UTGN/runs/CASP12/ProteinNet12Thinning90/\n","!mv /content/casp12.config /content/UTGN/UTGN/runs/CASP12/ProteinNet12Thinning90/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16878,"status":"ok","timestamp":1642379076392,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"IwclX9Noae4w","outputId":"f06c147f-73ba-48c6-88d5-825c4b7dc36e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/UTGN/UTGN/model\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"]}],"source":["%cd /content/UTGN/UTGN/model\n","!python main.py \"/content/UTGN/UTGN/runs/CASP12/ProteinNet12Thinning90/casp12.config\" -d \"/content/UTGN/UTGN/\" -c\n","#  Number of float values != expected.  values size: 42 but output shape: [20]"]},{"cell_type":"markdown","metadata":{"id":"yrQRxBjBjzie"},"source":["# RGN"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1642427690052,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"_lQEpLjsUWKQ","outputId":"4c3da3cb-a016-45b7-ffd5-feb51fd340a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Jan 17 13:57:13 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NlEmjdYrjzPe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'UTGN'...\n","remote: Enumerating objects: 490, done.\u001b[K\n","remote: Total 490 (delta 0), reused 0 (delta 0), pack-reused 490\u001b[K\n","Receiving objects: 100% (490/490), 57.67 MiB | 44.00 MiB/s, done.\n","Resolving deltas: 100% (335/335), done.\n","--2022-01-17 13:57:16--  https://sharehost.hms.harvard.edu/sysbio/alquraishi/rgn_models/RGN12.tar.gz\n","Resolving sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)... 134.174.159.103\n","Connecting to sharehost.hms.harvard.edu (sharehost.hms.harvard.edu)|134.174.159.103|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3095423957 (2.9G) [application/x-gzip]\n","Saving to: RGN12.tar.gz\n","\n","RGN12.tar.gz        100%[===================\u003e]   2.88G  38.6MB/s    in 43s     \n","\n","2022-01-17 13:57:59 (69.1 MB/s) - RGN12.tar.gz saved [3095423957/3095423957]\n","\n","Collecting tensorflow-gpu==1.15\n","  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n","\u001b[K     || 411.5 MB 7.5 kB/s \n","\u001b[?25hCollecting keras-applications\u003e=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     || 50 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio\u003e=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.43.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: astor\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: wrapt\u003e=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.13.3)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Collecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     || 503 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003c2.0,\u003e=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.19.5)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n","Requirement already satisfied: protobuf\u003e=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n","Requirement already satisfied: keras-preprocessing\u003e=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n","Requirement already satisfied: absl-py\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.12.0)\n","Collecting tensorboard\u003c1.16.0,\u003e=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     || 3.8 MB 78.0 MB/s \n","\u001b[?25hRequirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications\u003e=1.0.8-\u003etensorflow-gpu==1.15) (3.1.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (57.4.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.3.6)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (4.10.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.7.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow-gpu==1.15) (3.10.0.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py-\u003ekeras-applications\u003e=1.0.8-\u003etensorflow-gpu==1.15) (1.5.2)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=832da50a3af85a3eb8d5e7b05cba922bd7a719fbf663ea49aedb58df8459b248\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.7.0\n","    Uninstalling tensorflow-estimator-2.7.0:\n","      Successfully uninstalled tensorflow-estimator-2.7.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 1.15.0 which is incompatible.\n","tensorflow 2.7.0 requires tensorflow-estimator\u003c2.8,~=2.7.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n","tensorflow-probability 0.15.0 requires gast\u003e=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"]}],"source":["!git clone https://github.com/JinLi711/UTGN.git\n","!wget https://sharehost.hms.harvard.edu/sysbio/alquraishi/rgn_models/RGN12.tar.gz\n","!tar -xf RGN12.tar.gz\n","!mv /content/RGN12/* /content/UTGN/UTGN/\n","!pip install tensorflow-gpu==1.15\n"]},{"cell_type":"markdown","metadata":{"id":"aYhzGEuQmvSS"},"source":["change utils.py line 29"]},{"cell_type":"markdown","metadata":{"id":"NXbekZGhtISi"},"source":["add to config \n","\n","internal_representation transformer\n","transformer_layers 6\n","transformer_heads 8\n","transformer_ff_dims 256\n","transformer_dense_input_dim 256\n","transformer_type universal\n","act_max_steps 10\n","act_threshold 0.5\n","transition_function feed_forward\n","seperable_kernel_size 3\n","include_pos_encodings True\n","transformer_keep_prob 0.9\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13699,"status":"ok","timestamp":1642383617589,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"_TXW_CgWkm44","outputId":"284be111-8a34-415b-d1d3-f45deeff6779"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/UTGN/UTGN/model\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"]}],"source":["%cd /content/UTGN/UTGN/model\n","!python main.py \"/content/UTGN/UTGN/runs/CASP12/ProteinNet12Thinning90/configuration\" -d \"/content/UTGN/UTGN/\"\n","# recurrent\n","# No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) with these attrs: [dropout=0, seed=426, num_params=8, input_mode=\"linear_input\", T=DT_FLOAT, direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=4483]\n","# Registered devices: [CPU, XLA_CPU]\n","# Registered kernels:\n","#   device='GPU'; T in [DT_DOUBLE]\n","#   device='GPU'; T in [DT_FLOAT]\n","#   device='GPU'; T in [DT_HALF]\n","\n","# \t [[RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]]\n","\n","# transformer\n","# Traceback (most recent call last):\n","#   File \"main.py\", line 693, in \u003cmodule\u003e\n","#     while run_model(args): \n","#   File \"main.py\", line 491, in run_model\n","#     session = models['training'].start(list(models.values()))\n","#   File \"/content/UTGN/UTGN/model/model.py\", line 684, in _start\n","#     self._saver.restore(session, latest_checkpoint)\n","#   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 1306, in restore\n","#     err, \"a Variable name or other graph key that is missing\")\n","# tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n","\n","# Key RGN/RGN/dense/bias/Adam not found in checkpoint\n","# \t [[node save/RestoreV2 (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WuTnynH4rF33"},"outputs":[],"source":["# !mkdir -p /content/UTGN/UTGN/checkpoints/\n","%cp /content/UTGN/UTGN/runs/CASP12/ProteinNet12Thinning90/checkpoints/* /content/UTGN/UTGN/checkpoints/\n"]},{"cell_type":"markdown","metadata":{"id":"qjrxZum4zX4_"},"source":["## Predict"]},{"cell_type":"markdown","metadata":{"id":"HzBbXiPA0Ygf"},"source":["### New protien"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"931h8eXhzYXr"},"outputs":[],"source":["%cd /content/UTGN/UTGN/data_processing\n","# searches the supplied database for matches to the supplied sequence and extracts a PSSM out of the results. It will generate multiple new files.\n","!jackhmmer.sh \u003csequenceFile\u003e \u003cfastaDatabase\u003e\n","#  construct a text-based ProteinNet file (with 42 entries per evolutionary profile, compatible with the pre-trained UTGN models)\n","!python convert_to_proteinnet.py \u003csequenceFile\u003e\n","# converts the file to TFRecords format\n","!python convert_to_tfrecord.py \u003csequenceFile\u003e.proteinnet \u003csequenceFile\u003e.tfrecord 42\n","# copies the file to the testing directory of a pre-trained model\n","%cp \u003csequenceFile\u003e.tfrecord baseDirectory/data/\u003cdatasetName\u003e/testing/\n","# predicts the structure using the pre-trained UTGN model\n"]},{"cell_type":"markdown","metadata":{"id":"2ob_aANI1ouK"},"source":["### Predict sequences in TFRecords format using a trained model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3634,"status":"ok","timestamp":1641303779316,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"ltfdy5ao206h","outputId":"22952b92-6b19-44bb-c689-37d74574782d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}],"source":["!python main.py \"/content/UTGN/UTGN/runs/CASP12/casp12/casp12.config\" -d \"/content/UTGN/UTGN/data/casp12\" -p # -e weighted_testing for test set\n","# !python main.py baseDirectory/runs/\u003crunName\u003e/\u003cdatasetName\u003e/\u003cconfigurationFile\u003e -d baseDirectory -p -e weighted_testing"]},{"cell_type":"markdown","metadata":{"id":"9w7c5rfDXMbO"},"source":["current error\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgQqJKSR7kzV"},"outputs":[],"source":["*** Trainable Parameters: 2401521 ***\n","Traceback (most recent call last):\n","  File \"main.py\", line 693, in \u003cmodule\u003e\n","    while run_model(args): \n","  File \"main.py\", line 638, in run_model\n","    models['training'].finish(session, save=args.checkpoint_on_finish)\n","  File \"/content/UTGN/UTGN/model/model.py\", line 743, in _finish\n","    self._coordinator.join(self._threads)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/coordinator.py\", line 389, in join\n","    six.reraise(*self._exc_info_to_raise)\n","  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n","    raise value\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/queue_runner_impl.py\", line 257, in _run\n","    enqueue_callable()\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1287, in _single_operation_run\n","    self._call_tf_sessionrun(None, {}, [], target_list, None)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/UTGN/UTGN/data/casp12/training/90; Is a directory\n","\t [[{{node RGN/training/read_protein/ReaderReadV2}}]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8cLM-FCXd40"},"outputs":[],"source":["!mv /content/UTGN/UTGN/data/casp12/training/100 /content/\n","!mv /content/UTGN/UTGN/data/casp12/training/30 /content/\n","!mv /content/UTGN/UTGN/data/casp12/training/50 /content/\n","!mv /content/UTGN/UTGN/data/casp12/training/70 /content/\n","!mv /content/UTGN/UTGN/data/casp12/training/95 /content/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAbcuAvAX15t"},"outputs":[],"source":["!mv /content/UTGN/UTGN/data/casp12/training/pla/* /content/UTGN/UTGN/data/casp12/training/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1642377378017,"user":{"displayName":"Yomna Gamal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJJ5Qla5Q1bFYxQlp3maR5-cB1utYwwoojeVkw=s64","userId":"11878408275995395301"},"user_tz":-120},"id":"tNO8-2sjX_3M","outputId":"87314134-c0e7-4363-f239-495624d482c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove '/content/UTGN/UTGN/data/casp12/training/pla': Is a directory\n"]}],"source":["!rm /content/UTGN/UTGN/data/casp12/training/pla"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkHLCD7oYdjU"},"outputs":[],"source":["#  transformer\n","# *** Trainable Parameters: 2401521 ***\n","# Traceback (most recent call last):\n","#   File \"main.py\", line 693, in \u003cmodule\u003e\n","#     while run_model(args): \n","#   File \"main.py\", line 638, in run_model\n","#     models['training'].finish(session, save=args.checkpoint_on_finish)\n","#   File \"/content/UTGN/UTGN/model/model.py\", line 743, in _finish\n","#     self._coordinator.join(self._threads)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/coordinator.py\", line 389, in join\n","#     six.reraise(*self._exc_info_to_raise)\n","#   File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n","#     raise value\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/queue_runner_impl.py\", line 257, in _run\n","#     enqueue_callable()\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1287, in _single_operation_run\n","#     self._call_tf_sessionrun(None, {}, [], target_list, None)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","#     run_metadata)\n","# tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: evolutionary, Index: 0.  Number of float values != expected.  values size: 21 but output shape: [20]\n","# \t [[{{node RGN/training/read_protein/ParseSingleSequenceExample/ParseSingleSequenceExample}}]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsUUZX91WLgC"},"outputs":[],"source":["# # reccurent\n","# Traceback (most recent call last):\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","#     return fn(*args)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1348, in _run_fn\n","#     self._extend_graph()\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1388, in _extend_graph\n","#     tf_session.ExtendSession(self._session)\n","# tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by {{node RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams}}with these attrs: [rnn_mode=\"lstm\", seed2=4483, dropout=0, seed=426, num_params=8, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\"]\n","# Registered devices: [CPU, XLA_CPU]\n","# Registered kernels:\n","#   device='GPU'; T in [DT_DOUBLE]\n","#   device='GPU'; T in [DT_FLOAT]\n","#   device='GPU'; T in [DT_HALF]\n","\n","# \t [[RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]]\n","\n","# During handling of the above exception, another exception occurred:\n","\n","# Traceback (most recent call last):\n","#   File \"main.py\", line 693, in \u003cmodule\u003e\n","#     while run_model(args): \n","#   File \"main.py\", line 491, in run_model\n","#     session = models['training'].start(list(models.values()))\n","#   File \"/content/UTGN/UTGN/model/model.py\", line 681, in _start\n","#     tf.global_variables_initializer().run(session=session)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 2439, in run\n","#     _run_using_default_session(self, feed_dict, self.graph, session)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 5442, in _run_using_default_session\n","#     session.run(operation, feed_dict)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n","#     run_metadata_ptr)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n","#     feed_dict_tensor, options, run_metadata)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","#     run_metadata)\n","#   File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","#     raise type(e)(node_def, op, message)\n","# tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) with these attrs: [rnn_mode=\"lstm\", seed2=4483, dropout=0, seed=426, num_params=8, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\"]\n","# Registered devices: [CPU, XLA_CPU]\n","# Registered kernels:\n","#   device='GPU'; T in [DT_DOUBLE]\n","#   device='GPU'; T in [DT_FLOAT]\n","#   device='GPU'; T in [DT_HALF]\n","\n","# \t [[RGN/training/layer0/fw/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]]\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUGuMK2+8ERX4RqHA5sCJz","collapsed_sections":["Az0q8LUjxQPF"],"name":"Project.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}